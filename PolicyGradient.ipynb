{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy.random as rand\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def theta_policy(n_states, n_actions) : \n",
    "    theta = np.zeros((n_states, n_actions))    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\theta  - \\textrm{ parametrized policy}, \\theta \\in R^{ n \\times k }, \\textrm{where} $$\n",
    "$$ n=|S| - \\text{number of states} ,$$\n",
    "$$ k=|A| - \\text{number of actions} , $$\n",
    "$$ \\theta_{ij}   - \\textrm{ policy for state i  and action j }$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "theta = theta_policy(5, 2)\n",
    "print theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mu_policy( theta  ):\n",
    "    n_states, n_actions = theta.shape\n",
    "    mu  = np.zeros((n_states, n_actions))\n",
    "    for state in range(0, n_states) : \n",
    "        max_theta = np.max(theta[state])\n",
    "        mu[state] = np.exp(theta[state]-max_theta) / np.sum(np.exp(theta[state] - max_theta))\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mu - \\text{softmax policy} $$\n",
    "$$ $$ \n",
    "$$ \\mu(a=j | s=i; \\theta) = \\mu_{\\theta}(i,j) $$\n",
    "$$ $$\n",
    "$$  \\mu_{\\theta}(i,j)   =  \\frac{\\exp{\\theta_{ij}}}{\\sum_t{\\exp{\\theta_{it}}}} \\ $$\n",
    "\n",
    "$\\text{ computed using sum-exp trick} : $\n",
    "\n",
    "$$  \\frac{\\exp{\\theta_{ij}}}{\\sum_t{\\exp{\\theta_{it}}}} = \\frac{\\exp{\\theta_{ij}} \\times \\exp{(-a)}}{\\sum_t{\\exp{\\theta_{it}}} \\times \\exp{(-a)} } =  \\frac{\\exp{(\\theta_{ij} - a)}}{\\sum_t{\\exp{(\\theta_{it} - a)}}} $$\n",
    "\n",
    "$$ a = \\max_{t}{\\theta_{it}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]]\n"
     ]
    }
   ],
   "source": [
    "mu = mu_policy(theta)\n",
    "print mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_mu_policy( theta  ):\n",
    "    n_states, n_actions = theta.shape\n",
    "    log_mu  = np.zeros((n_states, n_actions))\n",
    "    for state in range(0, n_states) : \n",
    "        max_theta = np.max(theta[state])\n",
    "        log_sum_exp = max_theta  +  np.log(np.sum(np.exp(theta[state] - max_theta)))\n",
    "        log_mu[state] = theta[state] - log_sum_exp\n",
    "    return log_mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\log \\mu_{\\theta}(i,j)   = \\log \\frac{\\exp{\\theta_{ij}}}{\\sum_t{\\exp{\\theta_{it}}}} \\  = \\theta_{ij}  - \\log \\sum_t{\\exp{\\theta_{it}}}  = \\theta_{ij} - ( a + \\log \\sum_t{\\exp{(\\theta_{it}-a})}  )$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69314718 -0.69314718]\n",
      " [-0.69314718 -0.69314718]\n",
      " [-0.69314718 -0.69314718]\n",
      " [-0.69314718 -0.69314718]\n",
      " [-0.69314718 -0.69314718]]\n"
     ]
    }
   ],
   "source": [
    "log_mu = log_mu_policy(theta)\n",
    "print log_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_log_mu_policy(theta, mu ,  state, action) :\n",
    "    n_states, n_actions = theta.shape\n",
    "    grad  = np.zeros((n_states, n_actions))\n",
    "    grad[state, action] = 1 \n",
    "    max_theta = np.max(theta[state])\n",
    "    grad[state] = grad[state] - mu[state]\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\nabla \\log \\mu_{\\theta}(i,j)  = \\nabla( \\theta_{ij}  - \\log \\sum_t{\\exp{\\theta_{it}}} )  = \\begin{pmatrix}\n",
    "  \\frac{\\partial \\log \\mu_{\\theta}(i,j)} {\\partial \\theta_{11}}  &  \\frac{\\partial \\log \\mu_{\\theta}(i,j)} {\\partial \\theta_{12}} & \\cdots &  \\frac{\\partial \\log \\mu_{\\theta}(i,j)} {\\partial \\theta_{1m}} \\\\\n",
    "  \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "  \\frac{\\partial \\log \\mu_{\\theta}(i,j)} {\\partial \\theta_{n1}} &  \\frac{\\partial \\log \\mu_{\\theta}(i,j)} {\\partial \\theta_{n2}} & \\cdots & \\frac{\\partial \\log \\mu_{\\theta}(i,j)} {\\partial \\theta_{nm}} \n",
    " \\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial ( \\log \\sum_t{\\exp{\\theta_{pt}}} ) } {\\partial \\theta_{pl}} =  \\frac{\\exp{\\theta_{pl}}}{\\sum_t{\\exp{\\theta_{pt}}} }  = \\mu_{\\theta}(p,l) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial \\log \\mu_{\\theta}(i,j)} {\\partial \\theta_{pl}} =  \\frac{\\partial ( \\theta_{ij}  - \\log \\sum_t{\\exp{\\theta_{it}}} ) } {\\partial \\theta_{pl}}  =  \\begin{cases}\n",
    "    1 -  \\mu_{\\theta}(p,l)      & \\quad \\text{if } i=p, j=l \\\\\n",
    "    -  \\mu_{\\theta}(p,l)     & \\quad \\text{if } i=p, j \\ne l \\\\\n",
    "    0                           & \\quad \\text{if }  i \\ne p, j \\ne l  \\\\\n",
    "  \\end{cases} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient log mu :\n",
      "[[ 0.   0. ]\n",
      " [-0.5  0.5]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]]\n",
      "mu policy after adding gradient :\n",
      "[[ 0.5         0.5       ]\n",
      " [ 0.26894142  0.73105858]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "print \"gradient log mu :\\n\", gradient_log_mu_policy(theta, mu, 1, 1)\n",
    "print \"mu policy after adding gradient :\\n\" , mu_policy(theta + gradient_log_mu_policy(theta, mu, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def path_likelihood_ratio(theta_policy, mu_policy, path_states,  path_actions ) :\n",
    "    likelihood_ratio = np.zeros(theta_policy.shape)\n",
    "    path_len = len(path_states)\n",
    "    for t in range(0, path_len) :\n",
    "        likelihood_ratio = likelihood_ratio + gradient_log_mu_policy(theta_policy, mu_policy , path_states[t] , path_actions[t])\n",
    "    return likelihood_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likelihood ratio of path: \n",
    "$$ u(\\xi;\\theta)  =  \\sum_t{ \\nabla \\log \\mu_{\\theta}(s_t,a_t) } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]]\n",
      "path state    :  [2 0 1 2 3]\n",
      "path  actions :  [1 0 0 0 1]\n",
      "path reward :  1.6561\n",
      "path likelihood ratio: \n",
      "[[ 0.5 -0.5]\n",
      " [ 0.5 -0.5]\n",
      " [ 0.   0. ]\n",
      " [-0.5  0.5]\n",
      " [ 0.   0. ]]\n",
      "path state    :  [3 0 1 0 0]\n",
      "path  actions :  [1 0 1 0 1]\n",
      "path reward :  1.81\n",
      "path likelihood ratio: \n",
      "[[ 0.5 -0.5]\n",
      " [-0.5  0.5]\n",
      " [ 0.   0. ]\n",
      " [-0.5  0.5]\n",
      " [ 0.   0. ]]\n",
      "path state    :  [2 3 4 4 4]\n",
      "path  actions :  [0 0 0 0 1]\n",
      "path reward :  7.4682\n",
      "path likelihood ratio: \n",
      "[[ 0.   0. ]\n",
      " [ 0.   0. ]\n",
      " [ 0.5 -0.5]\n",
      " [ 0.5 -0.5]\n",
      " [ 0.5 -0.5]]\n",
      "path state    :  [2 0 1 2 3]\n",
      "path  actions :  [0 0 0 0 0]\n",
      "path reward :  0.0\n",
      "path likelihood ratio: \n",
      "[[ 0.5 -0.5]\n",
      " [ 0.5 -0.5]\n",
      " [ 1.  -1. ]\n",
      " [ 0.5 -0.5]\n",
      " [ 0.   0. ]]\n",
      "path state    :  [0 0 1 2 0]\n",
      "path  actions :  [1 0 0 1 0]\n",
      "path reward :  0.729\n",
      "path likelihood ratio: \n",
      "[[ 0.5 -0.5]\n",
      " [ 0.5 -0.5]\n",
      " [-0.5  0.5]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]]\n",
      "path state    :  [2 0 1 0 1]\n",
      "path  actions :  [1 0 1 0 0]\n",
      "path reward :  1.81\n",
      "path likelihood ratio: \n",
      "[[ 1.  -1. ]\n",
      " [ 0.   0. ]\n",
      " [-0.5  0.5]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]]\n",
      "path state    :  [4 0 1 0 1]\n",
      "path  actions :  [1 0 1 0 1]\n",
      "path reward :  3.4661\n",
      "path likelihood ratio: \n",
      "[[ 1.  -1. ]\n",
      " [-1.   1. ]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]\n",
      " [-0.5  0.5]]\n",
      "path state    :  [3 0 0 1 0]\n",
      "path  actions :  [1 1 0 1 0]\n",
      "path reward :  1.729\n",
      "path likelihood ratio: \n",
      "[[ 0.5 -0.5]\n",
      " [-0.5  0.5]\n",
      " [ 0.   0. ]\n",
      " [-0.5  0.5]\n",
      " [ 0.   0. ]]\n",
      "path state    :  [1 2 3 0 1]\n",
      "path  actions :  [0 0 1 0 0]\n",
      "path reward :  0.81\n",
      "path likelihood ratio: \n",
      "[[ 0.5 -0.5]\n",
      " [ 1.  -1. ]\n",
      " [ 0.5 -0.5]\n",
      " [-0.5  0.5]\n",
      " [ 0.   0. ]]\n",
      "path state    :  [1 2 0 0 0]\n",
      "path  actions :  [0 1 1 1 1]\n",
      "path reward :  0.9\n",
      "path likelihood ratio: \n",
      "[[-1.5  1.5]\n",
      " [ 0.5 -0.5]\n",
      " [-0.5  0.5]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "print mu\n",
    "for i in range(0, paths_states.shape[0]) :\n",
    "    print \"path state    : \",paths_states[i]\n",
    "    print \"path  actions : \",paths_actions[i]\n",
    "    print \"path reward : \",paths_rewards[i]\n",
    "    print \"path likelihood ratio: \\n\", path_likelihood_ratio(theta, mu, paths_states[i], paths_actions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def policy_gradient(theta_policy, mu_policy , paths_states , paths_actions, paths_rewards) :\n",
    "    policy_grad = np.zeros(theta_policy.shape)\n",
    "    n_paths , path_len =  paths_states.shape\n",
    "    for path in range(0, n_paths) :\n",
    "        policy_grad = policy_grad + paths_rewards[path]*path_likelihood_ratio(theta_policy, mu_policy, paths_states[path], paths_actions[path])\n",
    "    policy_grad = policy_grad/n_paths\n",
    "    return policy_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Policy gradient estimation :  \n",
    "$$ \\nabla \\eta(\\theta)  =  \\frac{1}{M} \\sum_m \\rho(\\xi_m) \\sum_t{ \\nabla \\log \\mu_{\\theta}(s_{mt},a_{mt}) } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current policy mu : \n",
      "[[ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]]\n",
      "generated trajectories : \n",
      " states :\n",
      "[[1 0 0 1 0]\n",
      " [3 4 4 0 0]\n",
      " [3 0 0 1 2]\n",
      " [3 4 0 1 0]\n",
      " [1 2 0 0 1]\n",
      " [3 0 0 0 0]\n",
      " [4 0 1 0 1]\n",
      " [3 0 0 1 0]\n",
      " [2 3 4 4 4]\n",
      " [4 0 1 0 1]] \n",
      " actions :\n",
      "[[0 1 0 0 1]\n",
      " [0 0 1 1 0]\n",
      " [1 1 0 0 0]\n",
      " [0 1 0 1 1]\n",
      " [0 1 1 0 1]\n",
      " [1 1 1 1 0]\n",
      " [0 0 1 0 0]\n",
      " [1 1 0 1 1]\n",
      " [0 0 0 0 1]\n",
      " [1 0 1 0 1]] \n",
      " rewards :\n",
      "[ 0.      5.22    1.      2.529   1.5561  1.      4.81    1.729   7.4682\n",
      "  3.4661]\n",
      "policy gradient : \n",
      "[[ 0.64116  -0.64116 ]\n",
      " [-0.50951   0.50951 ]\n",
      " [ 0.345605 -0.345605]\n",
      " [ 0.57441  -0.57441 ]\n",
      " [ 0.314155 -0.314155]]\n",
      "new mu policy : \n",
      "[[ 0.78284443  0.21715557]\n",
      " [ 0.26521834  0.73478166]\n",
      " [ 0.66623604  0.33376396]\n",
      " [ 0.75929532  0.24070468]\n",
      " [ 0.65210616  0.34789384]]\n"
     ]
    }
   ],
   "source": [
    "print \"current policy mu : \\n\", mu_policy(theta)\n",
    "print \"generated trajectories : \\n states :\\n\" , paths_states, '\\n actions :\\n',  paths_actions, '\\n rewards :\\n', paths_rewards\n",
    "print \"policy gradient : \\n\",  policy_gradient(theta , mu, paths_states, paths_actions , paths_rewards)\n",
    "print \"new mu policy : \\n\",  mu_policy(theta + policy_gradient(theta , mu, paths_states, paths_actions , paths_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def policy_gradient_algo(transitions, rewards, discount, path_len=10,  n_paths=100, gamma=1.0, eps=0.01, n_iterations=100, logging=False) : \n",
    "    n_states, n_actions = rewards.shape\n",
    "    theta = theta_policy(n_states, n_actions)\n",
    "    mu = mu_policy(theta)\n",
    "    n=0\n",
    "    paths_states, paths_actions, paths_rewards = generate_rollouts(mu, transitions, rewards, discount , path_len, n_paths )\n",
    "    pgrad = policy_gradient(theta, mu,  paths_states, paths_actions, paths_rewards) \n",
    "    theta_diff =  (gamma/(n+1))*pgrad \n",
    "    theta_diff_norm = np.linalg.norm(theta_diff)\n",
    "    #mu_diff = np.linalg.norm(mu_policy(theta) - mu_policy(theta+pgrad))\n",
    "    while ( (n<n_iterations) & (theta_diff_norm>eps) ):\n",
    "        if (logging) :\n",
    "            print \"mu policy : \\n\",  mu_policy(theta)\n",
    "            print \"policy gradient: \\n\", pgrad\n",
    "            print \"theta policy : \\n\" , theta_diff\n",
    "            print \"theta policy diff norm: \" , theta_diff_norm\n",
    "        theta_diff =  (gamma/(n+1))*pgrad\n",
    "        theta = theta + theta_diff\n",
    "        mu = mu_policy(theta)\n",
    "        paths_states, paths_actions, paths_rewards = generate_rollouts(mu_policy(theta), transitions, rewards, discount , path_len, n_paths )\n",
    "        pgrad = policy_gradient(theta, mu , paths_states, paths_actions, paths_rewards)\n",
    "        #mu_diff = np.linalg.norm(mu_policy(theta) - mu_policy(theta+pgrad))\n",
    "        theta_diff_norm = np.linalg.norm(theta_diff) \n",
    "        n = n+1\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat\n",
    "$$ \\theta^{n+1} = \\theta^{n} + \\frac {\\gamma}{n}  * \\nabla \\eta(\\theta^n) $$\n",
    "until \n",
    "$$ || \\theta_{n+1} - \\theta_{n} || > \\epsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu policy : \n",
      "[[ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]\n",
      " [ 0.5  0.5]]\n",
      "policy gradient: \n",
      "[[ 0.53215766 -0.53215766]\n",
      " [-0.17694584  0.17694584]\n",
      " [-0.06050809  0.06050809]\n",
      " [ 0.10145478 -0.10145478]\n",
      " [ 0.07098073 -0.07098073]]\n",
      "theta policy : \n",
      "[[ 5.32157658 -5.32157658]\n",
      " [-1.76945838  1.76945838]\n",
      " [-0.60508089  0.60508089]\n",
      " [ 1.01454779 -1.01454779]\n",
      " [ 0.70980729 -0.70980729]]\n",
      "theta policy diff norm:  8.16693538348\n",
      "mu policy : \n",
      "[[  9.99976137e-01   2.38631046e-05]\n",
      " [  2.82249844e-02   9.71775016e-01]\n",
      " [  2.29672426e-01   7.70327574e-01]\n",
      " [  8.83818241e-01   1.16181759e-01]\n",
      " [  8.05277987e-01   1.94722013e-01]]\n",
      "policy gradient: \n",
      "[[  4.59028693e-04  -4.59028693e-04]\n",
      " [ -5.36199539e-02   5.36199539e-02]\n",
      " [  2.42683882e-01  -2.42683882e-01]\n",
      " [  2.27021107e-01  -2.27021107e-01]\n",
      " [  1.79306808e+00  -1.79306808e+00]]\n",
      "theta policy : \n",
      "[[ 5.32157658 -5.32157658]\n",
      " [-1.76945838  1.76945838]\n",
      " [-0.60508089  0.60508089]\n",
      " [ 1.01454779 -1.01454779]\n",
      " [ 0.70980729 -0.70980729]]\n",
      "theta policy diff norm:  8.16693538348\n",
      "mu policy : \n",
      "[[  9.99976246e-01   2.37538198e-05]\n",
      " [  1.67063931e-02   9.83293607e-01]\n",
      " [  7.71478241e-01   2.28521759e-01]\n",
      " [  9.86603922e-01   1.33960784e-02]\n",
      " [  9.99999996e-01   3.94705782e-09]]\n",
      "policy gradient: \n",
      "[[  4.39298284e-04  -4.39298284e-04]\n",
      " [  1.06788879e-01  -1.06788879e-01]\n",
      " [  4.56136904e-01  -4.56136904e-01]\n",
      " [  4.41058749e-02  -4.41058749e-02]\n",
      " [  2.88778914e-07  -2.88778916e-07]]\n",
      "theta policy : \n",
      "[[  2.29514346e-03  -2.29514346e-03]\n",
      " [ -2.68099770e-01   2.68099770e-01]\n",
      " [  1.21341941e+00  -1.21341941e+00]\n",
      " [  1.13510554e+00  -1.13510554e+00]\n",
      " [  8.96534041e+00  -8.96534041e+00]]\n",
      "theta policy diff norm:  12.9003924441\n",
      "mu policy : \n",
      "[[  9.99976316e-01   2.36843564e-05]\n",
      " [  3.34658721e-02   9.66534128e-01]\n",
      " [  9.86041224e-01   1.39587762e-02]\n",
      " [  9.89982422e-01   1.00175781e-02]\n",
      " [  9.99999996e-01   3.94705022e-09]]\n",
      "policy gradient: \n",
      "[[  3.90475849e-04  -3.90475849e-04]\n",
      " [  4.26905796e-01  -4.26905796e-01]\n",
      " [  4.17129090e-02  -4.17129090e-02]\n",
      " [  4.06343708e-02  -4.06343708e-02]\n",
      " [  3.17996838e-07  -3.17996836e-07]]\n",
      "theta policy : \n",
      "[[  1.46432761e-03  -1.46432761e-03]\n",
      " [  3.55962930e-01  -3.55962930e-01]\n",
      " [  1.52045635e+00  -1.52045635e+00]\n",
      " [  1.47019583e-01  -1.47019583e-01]\n",
      " [  9.62596380e-07  -9.62596387e-07]]\n",
      "theta policy diff norm:  2.21815870183\n",
      "mu policy : \n",
      "[[  9.99976362e-01   2.36381618e-05]\n",
      " [  2.26415788e-01   7.73584212e-01]\n",
      " [  9.88639129e-01   1.13608712e-02]\n",
      " [  9.91809188e-01   8.19081219e-03]\n",
      " [  9.99999996e-01   3.94704395e-09]]\n",
      "policy gradient: \n",
      "[[  2.82848146e-04  -2.82848146e-04]\n",
      " [  1.16409584e+00  -1.16409584e+00]\n",
      " [  6.48950077e-02  -6.48950077e-02]\n",
      " [  7.48420969e-02  -7.48420969e-02]\n",
      " [  3.41060114e-07  -3.41060107e-07]]\n",
      "theta policy : \n",
      "[[  9.76189623e-04  -9.76189623e-04]\n",
      " [  1.06726449e+00  -1.06726449e+00]\n",
      " [  1.04282272e-01  -1.04282272e-01]\n",
      " [  1.01585927e-01  -1.01585927e-01]\n",
      " [  7.94992095e-07  -7.94992091e-07]]\n",
      "theta policy diff norm:  1.5233180466\n",
      "mu policy : \n",
      "[[  9.99976389e-01   2.36114335e-05]\n",
      " [  9.68559770e-01   3.14402304e-02]\n",
      " [  9.91213681e-01   8.78631877e-03]\n",
      " [  9.93915370e-01   6.08463048e-03]\n",
      " [  9.99999996e-01   3.94703856e-09]]\n",
      "policy gradient: \n",
      "[[  1.89846122e-04  -1.89846122e-04]\n",
      " [ -2.17597731e-01   2.17597731e-01]\n",
      " [  3.89505660e-02  -3.89505660e-02]\n",
      " [  7.59868252e-02  -7.59868252e-02]\n",
      " [  3.75478849e-07  -3.75478858e-07]]\n",
      "theta policy : \n",
      "[[  5.65696291e-04  -5.65696291e-04]\n",
      " [  2.32819168e+00  -2.32819168e+00]\n",
      " [  1.29790015e-01  -1.29790015e-01]\n",
      " [  1.49684194e-01  -1.49684194e-01]\n",
      " [  6.82120228e-07  -6.82120215e-07]]\n",
      "theta policy diff norm:  3.30445989848\n",
      "mu policy : \n",
      "[[  9.99976404e-01   2.35964968e-05]\n",
      " [  9.37167886e-01   6.28321140e-02]\n",
      " [  9.92275238e-01   7.72476189e-03]\n",
      " [  9.95270408e-01   4.72959221e-03]\n",
      " [  9.99999996e-01   3.94703362e-09]]\n",
      "policy gradient: \n",
      "[[  2.23764840e-04  -2.23764840e-04]\n",
      " [  4.37700516e-01  -4.37700516e-01]\n",
      " [  8.13659944e-02  -8.13659944e-02]\n",
      " [  2.05018000e-02  -2.05018000e-02]\n",
      " [  3.78787486e-07  -3.78787490e-07]]\n",
      "theta policy : \n",
      "[[  3.16410204e-04  -3.16410204e-04]\n",
      " [ -3.62662885e-01   3.62662885e-01]\n",
      " [  6.49176100e-02  -6.49176100e-02]\n",
      " [  1.26644709e-01  -1.26644709e-01]\n",
      " [  6.25798082e-07  -6.25798096e-07]]\n",
      "theta policy diff norm:  0.550958522556\n",
      "mu policy : \n",
      "[[  9.99976419e-01   2.35814160e-05]\n",
      " [  9.81163988e-01   1.88360122e-02]\n",
      " [  9.93867758e-01   6.13224161e-03]\n",
      " [  9.95538293e-01   4.46170748e-03]\n",
      " [  9.99999996e-01   3.94702935e-09]]\n",
      "policy gradient: \n",
      "[[  2.32595572e-04  -2.32595572e-04]\n",
      " [ -1.19202654e-01   1.19202654e-01]\n",
      " [ -2.07533240e-01   2.07533240e-01]\n",
      " [  5.14763870e-02  -5.14763870e-02]\n",
      " [  3.61978812e-07  -3.61978810e-07]]\n",
      "theta policy : \n",
      "[[  3.19664057e-04  -3.19664057e-04]\n",
      " [  6.25286452e-01  -6.25286452e-01]\n",
      " [  1.16237135e-01  -1.16237135e-01]\n",
      " [  2.92882857e-02  -2.92882857e-02]\n",
      " [  5.41124981e-07  -5.41124985e-07]]\n",
      "theta policy diff norm:  0.900391163943\n",
      "mu policy : \n",
      "[[  9.99976432e-01   2.35677080e-05]\n",
      " [  9.74789535e-01   2.52104651e-02]\n",
      " [  9.89740216e-01   1.02597842e-02]\n",
      " [  9.96074948e-01   3.92505155e-03]\n",
      " [  9.99999996e-01   3.94702578e-09]]\n",
      "policy gradient: \n",
      "[[  2.47478147e-04  -2.47478147e-04]\n",
      " [  3.75035222e-03  -3.75035222e-03]\n",
      " [  1.13760094e-01  -1.13760094e-01]\n",
      " [  4.97186728e-02  -4.97186728e-02]\n",
      " [  3.29675404e-07  -3.29675401e-07]]\n",
      "theta policy : \n",
      "[[  2.90744465e-04  -2.90744465e-04]\n",
      " [ -1.49003317e-01   1.49003317e-01]\n",
      " [ -2.59416549e-01   2.59416549e-01]\n",
      " [  6.43454838e-02  -6.43454838e-02]\n",
      " [  4.52473515e-07  -4.52473513e-07]]\n",
      "theta policy diff norm:  0.432757115484\n",
      "mu policy : \n",
      "[[  9.99976445e-01   2.35547508e-05]\n",
      " [  9.74993537e-01   2.50064634e-02]\n",
      " [  9.92013712e-01   7.98628762e-03]\n",
      " [  9.96484070e-01   3.51593043e-03]\n",
      " [  9.99999996e-01   3.94702289e-09]]\n",
      "policy gradient: \n",
      "[[  2.59134869e-04  -2.59134869e-04]\n",
      " [  4.09984982e-03  -4.09984982e-03]\n",
      " [ -2.90632930e-02   2.90632930e-02]\n",
      " [  3.60584957e-02  -3.60584957e-02]\n",
      " [  3.00073721e-07  -3.00073718e-07]]\n",
      "theta policy : \n",
      "[[  2.74975719e-04  -2.74975719e-04]\n",
      " [  4.16705802e-03  -4.16705802e-03]\n",
      " [  1.26400104e-01  -1.26400104e-01]\n",
      " [  5.52429697e-02  -5.52429697e-02]\n",
      " [  3.66306005e-07  -3.66306001e-07]]\n",
      "theta policy diff norm:  0.195172805735\n",
      "mu policy : \n",
      "[[  9.99976457e-01   2.35425465e-05]\n",
      " [  9.75192678e-01   2.48073221e-02]\n",
      " [  9.91539784e-01   8.46021639e-03]\n",
      " [  9.96727900e-01   3.27209962e-03]\n",
      " [  9.99999996e-01   3.94702052e-09]]\n",
      "policy gradient: \n",
      "[[  2.42336513e-04  -2.42336513e-04]\n",
      " [  2.18248445e-01  -2.18248445e-01]\n",
      " [  7.99914074e-02  -7.99914074e-02]\n",
      " [  4.21490499e-02  -4.21490499e-02]\n",
      " [  3.49711002e-07  -3.49711005e-07]]\n",
      "theta policy : \n",
      "[[  2.59134869e-04  -2.59134869e-04]\n",
      " [  4.09984982e-03  -4.09984982e-03]\n",
      " [ -2.90632930e-02   2.90632930e-02]\n",
      " [  3.60584957e-02  -3.60584957e-02]\n",
      " [  3.00073721e-07  -3.00073718e-07]]\n",
      "theta policy diff norm:  0.0657535707725\n",
      "mu policy : \n",
      "[[  9.99976468e-01   2.35321759e-05]\n",
      " [  9.83181455e-01   1.68185447e-02]\n",
      " [  9.92676549e-01   7.32345080e-03]\n",
      " [  9.96968557e-01   3.03144270e-03]\n",
      " [  9.99999996e-01   3.94701801e-09]]\n",
      "policy gradient: \n",
      "[[  2.43864754e-04  -2.43864754e-04]\n",
      " [ -6.87028914e-02   6.87028914e-02]\n",
      " [ -1.60125501e-02   1.60125501e-02]\n",
      " [  3.68825099e-02  -3.68825099e-02]\n",
      " [  3.03269491e-07  -3.03269488e-07]]\n",
      "theta policy : \n",
      "[[  2.20305921e-04  -2.20305921e-04]\n",
      " [  1.98407677e-01  -1.98407677e-01]\n",
      " [  7.27194613e-02  -7.27194613e-02]\n",
      " [  3.83173181e-02  -3.83173181e-02]\n",
      " [  3.17919093e-07  -3.17919096e-07]]\n",
      "theta policy diff norm:  0.303716946096\n",
      "mu policy : \n",
      "[[  9.99976477e-01   2.35226137e-05]\n",
      " [  9.81179464e-01   1.88205364e-02]\n",
      " [  9.92479962e-01   7.52003779e-03]\n",
      " [  9.97148776e-01   2.85122448e-03]\n",
      " [  9.99999996e-01   3.94701601e-09]]\n",
      "policy gradient: \n",
      "[[  2.10217118e-04  -2.10217118e-04]\n",
      " [  9.38658623e-02  -9.38658623e-02]\n",
      " [  7.73232755e-02  -7.73232755e-02]\n",
      " [  3.31385333e-02  -3.31385333e-02]\n",
      " [  4.19454683e-07  -4.19454679e-07]]\n",
      "theta policy : \n",
      "[[  2.03220629e-04  -2.03220629e-04]\n",
      " [ -5.72524095e-02   5.72524095e-02]\n",
      " [ -1.33437917e-02   1.33437917e-02]\n",
      " [  3.07354249e-02  -3.07354249e-02]\n",
      " [  2.52724576e-07  -2.52724573e-07]]\n",
      "theta policy diff norm:  0.093814741046\n",
      "mu policy : \n",
      "[[  9.99976485e-01   2.35150076e-05]\n",
      " [  9.83668863e-01   1.63311374e-02]\n",
      " [  9.93317741e-01   6.68225863e-03]\n",
      " [  9.97290110e-01   2.70988965e-03]\n",
      " [  9.99999996e-01   3.94701347e-09]]\n",
      "policy gradient: \n",
      "[[  2.19053933e-04  -2.19053933e-04]\n",
      " [  1.55794120e-01  -1.55794120e-01]\n",
      " [  6.51638146e-02  -6.51638146e-02]\n",
      " [  2.75750677e-02  -2.75750677e-02]\n",
      " [  3.78900505e-07  -3.78900513e-07]]\n",
      "theta policy : \n",
      "[[  1.61705475e-04  -1.61705475e-04]\n",
      " [  7.22045094e-02  -7.22045094e-02]\n",
      " [  5.94794427e-02  -5.94794427e-02]\n",
      " [  2.54911794e-02  -2.54911794e-02]\n",
      " [  3.22657448e-07  -3.22657446e-07]]\n",
      "theta policy diff norm:  0.137121272314\n",
      "mu policy : \n",
      "[[  9.99976492e-01   2.35076503e-05]\n",
      " [  9.86884766e-01   1.31152344e-02]\n",
      " [  9.93908106e-01   6.09189406e-03]\n",
      " [  9.97394513e-01   2.60548709e-03]\n",
      " [  9.99999996e-01   3.94701133e-09]]\n",
      "policy gradient: \n",
      "[[  2.04455391e-04  -2.04455391e-04]\n",
      " [  8.28827101e-02  -8.28827101e-02]\n",
      " [  6.34020354e-02  -6.34020354e-02]\n",
      " [  2.59992785e-02  -2.59992785e-02]\n",
      " [  3.76120582e-07  -3.76120577e-07]]\n",
      "theta policy : \n",
      "[[  1.56467095e-04  -1.56467095e-04]\n",
      " [  1.11281514e-01  -1.11281514e-01]\n",
      " [  4.65455819e-02  -4.65455819e-02]\n",
      " [  1.96964769e-02  -1.96964769e-02]\n",
      " [  2.70643218e-07  -2.70643224e-07]]\n",
      "theta policy diff norm:  0.172846997233\n",
      "mu policy : \n",
      "[[  9.99976499e-01   2.35012429e-05]\n",
      " [  9.88240784e-01   1.17592163e-02]\n",
      " [  9.94399158e-01   5.60084197e-03]\n",
      " [  9.97483063e-01   2.51693707e-03]\n",
      " [  9.99999996e-01   3.94700935e-09]]\n",
      "policy gradient: \n",
      "[[  2.78549908e-04  -2.78549908e-04]\n",
      " [  6.47151266e-02  -6.47151266e-02]\n",
      " [ -1.02016166e-02   1.02016166e-02]\n",
      " [  3.30776670e-02  -3.30776670e-02]\n",
      " [  3.03126084e-07  -3.03126082e-07]]\n",
      "theta policy : \n",
      "[[  1.36303594e-04  -1.36303594e-04]\n",
      " [  5.52551401e-02  -5.52551401e-02]\n",
      " [  4.22680236e-02  -4.22680236e-02]\n",
      " [  1.73328524e-02  -1.73328524e-02]\n",
      " [  2.50747055e-07  -2.50747052e-07]]\n",
      "theta policy diff norm:  0.101391939279\n",
      "mu policy : \n",
      "[[  9.99976507e-01   2.34930617e-05]\n",
      " [  9.89144655e-01   1.08553452e-02]\n",
      " [  9.94327686e-01   5.67231363e-03]\n",
      " [  9.97584763e-01   2.41523739e-03]\n",
      " [  9.99999996e-01   3.94700786e-09]]\n",
      "policy gradient: \n",
      "[[  2.39148202e-04  -2.39148202e-04]\n",
      " [ -1.10923494e-03   1.10923494e-03]\n",
      " [  6.19700199e-02  -6.19700199e-02]\n",
      " [  3.10496862e-02  -3.10496862e-02]\n",
      " [  3.39969518e-07  -3.39969520e-07]]\n",
      "theta policy : \n",
      "[[  1.74093692e-04  -1.74093692e-04]\n",
      " [  4.04469541e-02  -4.04469541e-02]\n",
      " [ -6.37601038e-03   6.37601038e-03]\n",
      " [  2.06735419e-02  -2.06735419e-02]\n",
      " [  1.89453803e-07  -1.89453801e-07]]\n",
      "theta policy diff norm:  0.0648696423669\n",
      "mu policy : \n",
      "[[  9.99976514e-01   2.34864530e-05]\n",
      " [  9.89130634e-01   1.08693664e-02]\n",
      " [  9.94724412e-01   5.27558770e-03]\n",
      " [  9.97671195e-01   2.32880481e-03]\n",
      " [  9.99999996e-01   3.94700628e-09]]\n",
      "policy gradient: \n",
      "[[  2.00535470e-04  -2.00535470e-04]\n",
      " [  1.03468928e-01  -1.03468928e-01]\n",
      " [  5.13976481e-02  -5.13976481e-02]\n",
      " [  2.89249002e-02  -2.89249002e-02]\n",
      " [  3.64103097e-07  -3.64103097e-07]]\n",
      "theta policy : \n",
      "[[  1.40675413e-04  -1.40675413e-04]\n",
      " [ -6.52491142e-04   6.52491142e-04]\n",
      " [  3.64529529e-02  -3.64529529e-02]\n",
      " [  1.82645213e-02  -1.82645213e-02]\n",
      " [  1.99982070e-07  -1.99982071e-07]]\n",
      "theta policy diff norm:  0.0576689872749\n",
      "mu policy : \n",
      "[[  9.99976519e-01   2.34812205e-05]\n",
      " [  9.90299630e-01   9.70037048e-03]\n",
      " [  9.95015792e-01   4.98420778e-03]\n",
      " [  9.97744684e-01   2.25531591e-03]\n",
      " [  9.99999996e-01   3.94700468e-09]]\n",
      "policy gradient: \n",
      "[[  2.41501104e-04  -2.41501104e-04]\n",
      " [ -6.63002024e-02   6.63002024e-02]\n",
      " [  4.54882499e-02  -4.54882499e-02]\n",
      " [ -1.41566305e-02   1.41566305e-02]\n",
      " [  3.54905194e-07  -3.54905190e-07]]\n",
      "theta policy : \n",
      "[[  1.11408595e-04  -1.11408595e-04]\n",
      " [  5.74827377e-02  -5.74827377e-02]\n",
      " [  2.85542489e-02  -2.85542489e-02]\n",
      " [  1.60693890e-02  -1.60693890e-02]\n",
      " [  2.02279498e-07  -2.02279498e-07]]\n",
      "theta policy diff norm:  0.0935718755046\n",
      "mu policy : \n",
      "[[  9.99976525e-01   2.34752522e-05]\n",
      " [  9.89605749e-01   1.03942508e-02]\n",
      " [  9.95247717e-01   4.75228313e-03]\n",
      " [  9.97710902e-01   2.28909814e-03]\n",
      " [  9.99999996e-01   3.94700321e-09]]\n",
      "policy gradient: \n",
      "[[  2.18035738e-04  -2.18035738e-04]\n",
      " [ -4.91735362e-02   4.91735362e-02]\n",
      " [ -5.15102544e-02   5.15102544e-02]\n",
      " [  2.88735259e-02  -2.88735259e-02]\n",
      " [  3.05873629e-07  -3.05873632e-07]]\n",
      "theta policy : \n",
      "[[  1.27105844e-04  -1.27105844e-04]\n",
      " [ -3.48948434e-02   3.48948434e-02]\n",
      " [  2.39411841e-02  -2.39411841e-02]\n",
      " [ -7.45085815e-03   7.45085815e-03]\n",
      " [  1.86792207e-07  -1.86792205e-07]]\n",
      "theta policy diff norm:  0.0607677848177\n",
      "mu policy : \n",
      "[[  9.99976530e-01   2.34701345e-05]\n",
      " [  9.89087569e-01   1.09124312e-02]\n",
      " [  9.94997768e-01   5.00223214e-03]\n",
      " [  9.97775906e-01   2.22409377e-03]\n",
      " [  9.99999996e-01   3.94700200e-09]]\n",
      "policy gradient: \n",
      "[[  2.32460351e-04  -2.32460351e-04]\n",
      " [  1.02298959e-01  -1.02298959e-01]\n",
      " [  2.46724293e-02  -2.46724293e-02]\n",
      " [  2.50172863e-02  -2.50172863e-02]\n",
      " [  4.07284290e-07  -4.07284284e-07]]\n",
      "theta policy : \n",
      "[[  1.09017869e-04  -1.09017869e-04]\n",
      " [ -2.45867681e-02   2.45867681e-02]\n",
      " [ -2.57551272e-02   2.57551272e-02]\n",
      " [  1.44367630e-02  -1.44367630e-02]\n",
      " [  1.52936814e-07  -1.52936816e-07]]\n",
      "theta policy diff norm:  0.0543372386708\n",
      "mu policy : \n",
      "[[  9.99976535e-01   2.34649391e-05]\n",
      " [  9.90090553e-01   9.90944729e-03]\n",
      " [  9.95113370e-01   4.88662981e-03]\n",
      " [  9.97828157e-01   2.17184257e-03]\n",
      " [  9.99999996e-01   3.94700047e-09]]\n",
      "policy gradient: \n",
      "[[  2.56759001e-04  -2.56759001e-04]\n",
      " [  9.30787820e-02  -9.30787820e-02]\n",
      " [  2.72928885e-02  -2.72928885e-02]\n",
      " [  2.72036351e-02  -2.72036351e-02]\n",
      " [  3.97820934e-07  -3.97820930e-07]]\n",
      "theta policy : \n",
      "[[  1.10695405e-04  -1.10695405e-04]\n",
      " [  4.87137902e-02  -4.87137902e-02]\n",
      " [  1.17487759e-02  -1.17487759e-02]\n",
      " [  1.19129935e-02  -1.19129935e-02]\n",
      " [  1.93944900e-07  -1.93944897e-07]]\n",
      "theta policy diff norm:  0.072842278285\n",
      "mu policy : \n",
      "[[  9.99976541e-01   2.34594627e-05]\n",
      " [  9.90887238e-01   9.11276187e-03]\n",
      " [  9.95232553e-01   4.76744685e-03]\n",
      " [  9.97881097e-01   2.11890277e-03]\n",
      " [  9.99999996e-01   3.94699904e-09]]\n",
      "policy gradient: \n",
      "[[  2.26836571e-04  -2.26836571e-04]\n",
      " [ -4.34273165e-02   4.34273165e-02]\n",
      " [  4.74619586e-02  -4.74619586e-02]\n",
      " [  2.60210706e-02  -2.60210706e-02]\n",
      " [  3.66730063e-07  -3.66730072e-07]]\n",
      "theta policy : \n",
      "[[  1.16708637e-04  -1.16708637e-04]\n",
      " [  4.23085373e-02  -4.23085373e-02]\n",
      " [  1.24058584e-02  -1.24058584e-02]\n",
      " [  1.23652887e-02  -1.23652887e-02]\n",
      " [  1.80827697e-07  -1.80827696e-07]]\n",
      "theta policy diff norm:  0.0647584995606\n",
      "mu policy : \n",
      "[[  9.99976545e-01   2.34548359e-05]\n",
      " [  9.90539852e-01   9.46014846e-03]\n",
      " [  9.95424425e-01   4.57557518e-03]\n",
      " [  9.97928405e-01   2.07159488e-03]\n",
      " [  9.99999996e-01   3.94699778e-09]]\n",
      "policy gradient: \n",
      "[[  2.47429761e-04  -2.47429761e-04]\n",
      " [  1.12742075e-01  -1.12742075e-01]\n",
      " [  5.36930141e-02  -5.36930141e-02]\n",
      " [  2.79793205e-02  -2.79793205e-02]\n",
      " [  3.27521994e-07  -3.27521989e-07]]\n",
      "theta policy : \n",
      "[[  9.86245961e-05  -9.86245961e-05]\n",
      " [ -1.88814420e-02   1.88814420e-02]\n",
      " [  2.06356342e-02  -2.06356342e-02]\n",
      " [  1.13135090e-02  -1.13135090e-02]\n",
      " [  1.59447854e-07  -1.59447857e-07]]\n",
      "theta policy diff norm:  0.0426695080954\n",
      "mu policy : \n",
      "[[  9.99976550e-01   2.34500004e-05]\n",
      " [  9.91380862e-01   8.61913757e-03]\n",
      " [  9.95623766e-01   4.37623372e-03]\n",
      " [  9.97976051e-01   2.02394875e-03]\n",
      " [  9.99999996e-01   3.94699670e-09]]\n",
      "policy gradient: \n",
      "[[  2.36146351e-04  -2.36146351e-04]\n",
      " [ -5.35143336e-02   5.35143336e-02]\n",
      " [  4.88771009e-02  -4.88771009e-02]\n",
      " [  2.55474912e-02  -2.55474912e-02]\n",
      " [  3.36364714e-07  -3.36364711e-07]]\n",
      "theta policy : \n",
      "[[  1.03095734e-04  -1.03095734e-04]\n",
      " [  4.69758646e-02  -4.69758646e-02]\n",
      " [  2.23720892e-02  -2.23720892e-02]\n",
      " [  1.16580502e-02  -1.16580502e-02]\n",
      " [  1.36467497e-07  -1.36467495e-07]]\n",
      "theta policy diff norm:  0.0754077316592\n",
      "mu policy : \n",
      "[[  9.99976554e-01   2.34455708e-05]\n",
      " [  9.91007242e-01   8.99275773e-03]\n",
      " [  9.95790876e-01   4.20912431e-03]\n",
      " [  9.98016916e-01   1.98308434e-03]\n",
      " [  9.99999996e-01   3.94699564e-09]]\n",
      "policy gradient: \n",
      "[[  1.95990235e-04  -1.95990235e-04]\n",
      " [  8.48995134e-02  -8.48995134e-02]\n",
      " [  4.80012886e-02  -4.80012886e-02]\n",
      " [  2.69547639e-02  -2.69547639e-02]\n",
      " [  3.65966748e-07  -3.65966750e-07]]\n",
      "theta policy : \n",
      "[[  9.44585403e-05  -9.44585403e-05]\n",
      " [ -2.14057334e-02   2.14057334e-02]\n",
      " [  1.95508404e-02  -1.95508404e-02]\n",
      " [  1.02189965e-02  -1.02189965e-02]\n",
      " [  1.34545885e-07  -1.34545885e-07]]\n",
      "theta policy diff norm:  0.0434713145357\n",
      "mu policy : \n",
      "[[  9.99976558e-01   2.34420364e-05]\n",
      " [  9.91570977e-01   8.42902348e-03]\n",
      " [  9.95942840e-01   4.05715971e-03]\n",
      " [  9.98057531e-01   1.94246861e-03]\n",
      " [  9.99999996e-01   3.94699453e-09]]\n",
      "policy gradient: \n",
      "[[  2.22446407e-04  -2.22446407e-04]\n",
      " [  7.80791890e-02  -7.80791890e-02]\n",
      " [  1.33403645e-03  -1.33403645e-03]\n",
      " [  2.55804640e-02  -2.55804640e-02]\n",
      " [  3.88255302e-07  -3.88255304e-07]]\n",
      "theta policy : \n",
      "[[  7.53808597e-05  -7.53808597e-05]\n",
      " [  3.26536590e-02  -3.26536590e-02]\n",
      " [  1.84620341e-02  -1.84620341e-02]\n",
      " [  1.03672169e-02  -1.03672169e-02]\n",
      " [  1.40756442e-07  -1.40756442e-07]]\n",
      "theta policy diff norm:  0.0550380417021\n",
      "mu policy : \n",
      "[[  9.99976562e-01   2.34381742e-05]\n",
      " [  9.92040881e-01   7.95911870e-03]\n",
      " [  9.95946831e-01   4.05316875e-03]\n",
      " [  9.98093922e-01   1.90607778e-03]\n",
      " [  9.99999996e-01   3.94699340e-09]]\n",
      "policy gradient: \n",
      "[[  2.23535350e-04  -2.23535350e-04]\n",
      " [ -7.71066480e-02   7.71066480e-02]\n",
      " [  4.51094128e-02  -4.51094128e-02]\n",
      " [  2.31906572e-02  -2.31906572e-02]\n",
      " [  3.51534562e-07  -3.51534562e-07]]\n",
      "theta policy : \n",
      "[[  8.23875583e-05  -8.23875583e-05]\n",
      " [  2.89182181e-02  -2.89182181e-02]\n",
      " [  4.94087574e-04  -4.94087574e-04]\n",
      " [  9.47424593e-03  -9.47424593e-03]\n",
      " [  1.43798260e-07  -1.43798261e-07]]\n",
      "theta policy diff norm:  0.0430412729086\n",
      "mu policy : \n",
      "[[  9.99976566e-01   2.34344322e-05]\n",
      " [  9.91594015e-01   8.40598458e-03]\n",
      " [  9.96074842e-01   3.92515757e-03]\n",
      " [  9.98125177e-01   1.87482284e-03]\n",
      " [  9.99999996e-01   3.94699240e-09]]\n",
      "policy gradient: \n",
      "[[  1.91065724e-04  -1.91065724e-04]\n",
      " [  7.08648877e-02  -7.08648877e-02]\n",
      " [ -7.45362628e-02   7.45362628e-02]\n",
      " [  2.18419305e-02  -2.18419305e-02]\n",
      " [  3.76596194e-07  -3.76596184e-07]]\n",
      "theta policy : \n",
      "[[  7.98340535e-05  -7.98340535e-05]\n",
      " [ -2.75380886e-02   2.75380886e-02]\n",
      " [  1.61105046e-02  -1.61105046e-02]\n",
      " [  8.28237756e-03  -8.28237756e-03]\n",
      " [  1.25548058e-07  -1.25548058e-07]]\n",
      "theta policy diff norm:  0.0466154230031\n",
      "mu policy : \n",
      "[[  9.99976569e-01   2.34313446e-05]\n",
      " [  9.91991747e-01   8.00825263e-03]\n",
      " [  9.95868652e-01   4.13134819e-03]\n",
      " [  9.98153155e-01   1.84684504e-03]\n",
      " [  9.99999996e-01   3.94699138e-09]]\n",
      "policy gradient: \n",
      "[[ -1.63536655e-01   1.63536655e-01]\n",
      " [  8.56781571e-02  -8.56781571e-02]\n",
      " [  4.81355526e-02  -4.81355526e-02]\n",
      " [  2.25082606e-02  -2.25082606e-02]\n",
      " [  3.59280597e-07  -3.59280595e-07]]\n",
      "theta policy : \n",
      "[[  6.58847323e-05  -6.58847323e-05]\n",
      " [  2.44361682e-02  -2.44361682e-02]\n",
      " [ -2.57021596e-02   2.57021596e-02]\n",
      " [  7.53170018e-03  -7.53170018e-03]\n",
      " [  1.29860757e-07  -1.29860753e-07]]\n",
      "theta policy diff norm:  0.0512729591664\n",
      "mu policy : \n",
      "[[  9.99973870e-01   2.61303213e-05]\n",
      " [  9.92432986e-01   7.56701386e-03]\n",
      " [  9.95998602e-01   4.00139841e-03]\n",
      " [  9.98180611e-01   1.81938913e-03]\n",
      " [  9.99999996e-01   3.94699043e-09]]\n",
      "policy gradient: \n",
      "[[  2.46108891e-04  -2.46108891e-04]\n",
      " [  7.11457083e-02  -7.11457083e-02]\n",
      " [  4.02123781e-02  -4.02123781e-02]\n",
      " [  2.46086231e-02  -2.46086231e-02]\n",
      " [  3.58047901e-07  -3.58047894e-07]]\n",
      "theta policy : \n",
      "[[ -5.45122183e-02   5.45122183e-02]\n",
      " [  2.85593857e-02  -2.85593857e-02]\n",
      " [  1.60451842e-02  -1.60451842e-02]\n",
      " [  7.50275353e-03  -7.50275353e-03]\n",
      " [  1.19760199e-07  -1.19760198e-07]]\n",
      "theta policy diff norm:  0.0905644489296\n",
      "mu policy : \n",
      "[[  9.99973874e-01   2.61261728e-05]\n",
      " [  9.92770010e-01   7.22998961e-03]\n",
      " [  9.96100677e-01   3.89932287e-03]\n",
      " [  9.98209217e-01   1.79078295e-03]\n",
      " [  9.99999996e-01   3.94698952e-09]]\n",
      "policy gradient: \n",
      "[[  2.22849115e-04  -2.22849115e-04]\n",
      " [  8.02802527e-03  -8.02802527e-03]\n",
      " [ -3.67080395e-02   3.67080395e-02]\n",
      " [  2.39342279e-02  -2.39342279e-02]\n",
      " [  3.93466839e-07  -3.93466829e-07]]\n",
      "theta policy : \n",
      "[[  7.93899648e-05  -7.93899648e-05]\n",
      " [  2.29502285e-02  -2.29502285e-02]\n",
      " [  1.29717349e-02  -1.29717349e-02]\n",
      " [  7.93826552e-03  -7.93826552e-03]\n",
      " [  1.15499323e-07  -1.15499321e-07]]\n",
      "theta policy diff norm:  0.038935876901\n",
      "mu policy : \n",
      "[[  9.99973877e-01   2.61225342e-05]\n",
      " [  9.92805936e-01   7.19406420e-03]\n",
      " [  9.96010544e-01   3.98945627e-03]\n",
      " [  9.98235759e-01   1.76424110e-03]\n",
      " [  9.99999996e-01   3.94698855e-09]]\n",
      "policy gradient: \n",
      "[[  2.57264438e-04  -2.57264438e-04]\n",
      " [  7.22200244e-02  -7.22200244e-02]\n",
      " [  4.27439485e-02  -4.27439485e-02]\n",
      " [  2.02866438e-02  -2.02866438e-02]\n",
      " [  3.21355754e-07  -3.21355757e-07]]\n",
      "theta policy : \n",
      "[[  6.96403485e-05  -6.96403485e-05]\n",
      " [  2.50875790e-03  -2.50875790e-03]\n",
      " [ -1.14712623e-02   1.14712623e-02]\n",
      " [  7.47944620e-03  -7.47944620e-03]\n",
      " [  1.22958387e-07  -1.22958384e-07]]\n",
      "theta policy diff norm:  0.0196891183605\n",
      "mu policy : \n",
      "[[  9.99973882e-01   2.61184617e-05]\n",
      " [  9.93111904e-01   6.88809594e-03]\n",
      " [  9.96112168e-01   3.88783152e-03]\n",
      " [  9.98257280e-01   1.74272024e-03]\n",
      " [  9.99999996e-01   3.94698778e-09]]\n",
      "policy gradient: \n",
      "[[  3.04779890e-04  -3.04779890e-04]\n",
      " [  7.10990470e-02  -7.10990470e-02]\n",
      " [  4.34547869e-02  -4.34547869e-02]\n",
      " [  2.20968841e-02  -2.20968841e-02]\n",
      " [  2.87871643e-07  -2.87871639e-07]]\n",
      "theta policy : \n",
      "[[  7.79589205e-05  -7.79589205e-05]\n",
      " [  2.18848559e-02  -2.18848559e-02]\n",
      " [  1.29527117e-02  -1.29527117e-02]\n",
      " [  6.14746783e-03  -6.14746783e-03]\n",
      " [  9.73805315e-08  -9.73805324e-08]]\n",
      "theta policy diff norm:  0.0370004620068\n",
      "mu policy : \n",
      "[[  9.99973886e-01   2.61137797e-05]\n",
      " [  9.93392179e-01   6.60782073e-03]\n",
      " [  9.96209917e-01   3.79008345e-03]\n",
      " [  9.98279747e-01   1.72025337e-03]\n",
      " [  9.99999996e-01   3.94698711e-09]]\n",
      "policy gradient: \n",
      "[[  2.99180595e-04  -2.99180595e-04]\n",
      " [ -4.04596393e-02   4.04596393e-02]\n",
      " [  4.17819499e-02  -4.17819499e-02]\n",
      " [  2.19429764e-02  -2.19429764e-02]\n",
      " [  3.15386738e-07  -3.15386733e-07]]\n",
      "theta policy : \n",
      "[[  8.96411441e-05  -8.96411441e-05]\n",
      " [  2.09114844e-02  -2.09114844e-02]\n",
      " [  1.27808197e-02  -1.27808197e-02]\n",
      " [  6.49908357e-03  -6.49908357e-03]\n",
      " [  8.46681304e-08  -8.46681290e-08]]\n",
      "theta policy diff norm:  0.0358576534063\n",
      "mu policy : \n",
      "[[  9.99973891e-01   2.61093157e-05]\n",
      " [  9.93238673e-01   6.76132692e-03]\n",
      " [  9.96299004e-01   3.70099632e-03]\n",
      " [  9.98301146e-01   1.69885446e-03]\n",
      " [  9.99999996e-01   3.94698640e-09]]\n",
      "policy gradient: \n",
      "[[  2.52185043e-04  -2.52185043e-04]\n",
      " [  6.32723418e-02  -6.32723418e-02]\n",
      " [  4.04788117e-02  -4.04788117e-02]\n",
      " [  2.20199589e-02  -2.20199589e-02]\n",
      " [  3.39187875e-07  -3.39187865e-07]]\n",
      "theta policy : \n",
      "[[  8.54801700e-05  -8.54801700e-05]\n",
      " [ -1.15598969e-02   1.15598969e-02]\n",
      " [  1.19377000e-02  -1.19377000e-02]\n",
      " [  6.26942181e-03  -6.26942181e-03]\n",
      " [  9.01104966e-08  -9.01104951e-08]]\n",
      "theta policy diff norm:  0.0251178364827\n",
      "mu policy : \n",
      "[[  9.99973894e-01   2.61056581e-05]\n",
      " [  9.93470689e-01   6.52931102e-03]\n",
      " [  9.96381006e-01   3.61899417e-03]\n",
      " [  9.98321767e-01   1.67823312e-03]\n",
      " [  9.99999996e-01   3.94698566e-09]]\n",
      "policy gradient: \n",
      "[[  2.30191184e-04  -2.30191184e-04]\n",
      " [  6.18775206e-02  -6.18775206e-02]\n",
      " [  4.04650181e-02  -4.04650181e-02]\n",
      " [  2.16233629e-02  -2.16233629e-02]\n",
      " [  3.58819678e-07  -3.58819681e-07]]\n",
      "theta policy : \n",
      "[[  7.00514009e-05  -7.00514009e-05]\n",
      " [  1.75756505e-02  -1.75756505e-02]\n",
      " [  1.12441144e-02  -1.12441144e-02]\n",
      " [  6.11665525e-03  -6.11665525e-03]\n",
      " [  9.42188540e-08  -9.42188514e-08]]\n",
      "theta policy diff norm:  0.0307490480213\n",
      "mu policy : \n",
      "[[  9.99973898e-01   2.61024101e-05]\n",
      " [  9.93684108e-01   6.31589151e-03]\n",
      " [  9.96459027e-01   3.54097266e-03]\n",
      " [  9.98341236e-01   1.65876396e-03]\n",
      " [  9.99999996e-01   3.94698489e-09]]\n",
      "policy gradient: \n",
      "[[  1.90856503e-04  -1.90856503e-04]\n",
      " [  2.90424788e-02  -2.90424788e-02]\n",
      " [  3.43048176e-02  -3.43048176e-02]\n",
      " [  2.20041686e-02  -2.20041686e-02]\n",
      " [  4.12016535e-07  -4.12016528e-07]]\n",
      "theta policy : \n",
      "[[  6.22138336e-05  -6.22138336e-05]\n",
      " [  1.67236542e-02  -1.67236542e-02]\n",
      " [  1.09364914e-02  -1.09364914e-02]\n",
      " [  5.84415212e-03  -5.84415212e-03]\n",
      " [  9.69782913e-08  -9.69782921e-08]]\n",
      "theta policy diff norm:  0.0294430106568\n",
      "mu policy : \n",
      "[[  9.99973900e-01   2.60997883e-05]\n",
      " [  9.93779320e-01   6.22067994e-03]\n",
      " [  9.96522166e-01   3.47783386e-03]\n",
      " [  9.98360304e-01   1.63969571e-03]\n",
      " [  9.99999996e-01   3.94698404e-09]]\n",
      "policy gradient: \n",
      "[[  2.92670238e-04  -2.92670238e-04]\n",
      " [ -1.41622077e-02   1.41622077e-02]\n",
      " [  3.95819576e-02  -3.95819576e-02]\n",
      " [ -9.28120969e-02   9.28120969e-02]\n",
      " [  3.36785910e-07  -3.36785907e-07]]\n",
      "theta policy : \n",
      "[[  5.02253957e-05  -5.02253957e-05]\n",
      " [  7.64275758e-03  -7.64275758e-03]\n",
      " [  9.02758357e-03  -9.02758357e-03]\n",
      " [  5.79057068e-03  -5.79057068e-03]\n",
      " [  1.08425404e-07  -1.08425402e-07]]\n",
      "theta policy diff norm:  0.0186248350313\n",
      "mu policy : \n",
      "[[  9.99973904e-01   2.60958715e-05]\n",
      " [  9.93734261e-01   6.26573904e-03]\n",
      " [  9.96591811e-01   3.40818909e-03]\n",
      " [  9.98280512e-01   1.71948822e-03]\n",
      " [  9.99999996e-01   3.94698336e-09]]\n",
      "policy gradient: \n",
      "[[  2.58442254e-04  -2.58442254e-04]\n",
      " [  6.50375426e-02  -6.50375426e-02]\n",
      " [ -1.40884701e-01   1.40884701e-01]\n",
      " [  2.10156373e-02  -2.10156373e-02]\n",
      " [  3.59817967e-07  -3.59817963e-07]]\n",
      "theta policy : \n",
      "[[  7.50436507e-05  -7.50436507e-05]\n",
      " [ -3.63133531e-03   3.63133531e-03]\n",
      " [  1.01492199e-02  -1.01492199e-02]\n",
      " [ -2.37979736e-02   2.37979736e-02]\n",
      " [  8.63553616e-08  -8.63553609e-08]]\n",
      "theta policy diff norm:  0.0369470550544\n",
      "mu policy : \n",
      "[[  9.99973908e-01   2.60924996e-05]\n",
      " [  9.93933522e-01   6.06647839e-03]\n",
      " [  9.96343981e-01   3.65601858e-03]\n",
      " [  9.98298455e-01   1.70154533e-03]\n",
      " [  9.99999996e-01   3.94698265e-09]]\n",
      "policy gradient: \n",
      "[[  2.48729660e-04  -2.48729660e-04]\n",
      " [  5.58061347e-02  -5.58061347e-02]\n",
      " [  3.64365082e-02  -3.64365082e-02]\n",
      " [  1.98574452e-02  -1.98574452e-02]\n",
      " [  3.93145513e-07  -3.93145504e-07]]\n",
      "theta policy : \n",
      "[[  6.46105635e-05  -6.46105635e-05]\n",
      " [  1.62593857e-02  -1.62593857e-02]\n",
      " [ -3.52211753e-02   3.52211753e-02]\n",
      " [  5.25390932e-03  -5.25390932e-03]\n",
      " [  8.99544918e-08  -8.99544907e-08]]\n",
      "theta policy diff norm:  0.0553625603861\n",
      "mu policy : \n",
      "[[  9.99973911e-01   2.60893341e-05]\n",
      " [  9.94095477e-01   5.90452316e-03]\n",
      " [  9.96408158e-01   3.59184227e-03]\n",
      " [  9.98314830e-01   1.68517042e-03]\n",
      " [  9.99999996e-01   3.94698189e-09]]\n",
      "policy gradient: \n",
      "[[  2.34517386e-04  -2.34517386e-04]\n",
      " [  5.03664188e-02  -5.03664188e-02]\n",
      " [ -3.65746600e-02   3.65746600e-02]\n",
      " [  2.02320147e-02  -2.02320147e-02]\n",
      " [  3.76229339e-07  -3.76229342e-07]]\n",
      "theta policy : \n",
      "[[  6.06657707e-05  -6.06657707e-05]\n",
      " [  1.36112524e-02  -1.36112524e-02]\n",
      " [  8.88695323e-03  -8.88695323e-03]\n",
      " [  4.84327931e-03  -4.84327931e-03]\n",
      " [  9.58891496e-08  -9.58891473e-08]]\n",
      "theta policy diff norm:  0.0239877120038\n",
      "mu policy : \n",
      "[[  9.99973914e-01   2.60864208e-05]\n",
      " [  9.94234599e-01   5.76540052e-03]\n",
      " [  9.96345283e-01   3.65471692e-03]\n",
      " [  9.98330960e-01   1.66903992e-03]\n",
      " [  9.99999996e-01   3.94698118e-09]]\n",
      "policy gradient: \n",
      "[[  2.31713670e-04  -2.31713670e-04]\n",
      " [  7.21725026e-03  -7.21725026e-03]\n",
      " [  7.76051796e-03  -7.76051796e-03]\n",
      " [  2.22270511e-02  -2.22270511e-02]\n",
      " [  3.88560822e-07  -3.88560822e-07]]\n",
      "theta policy : \n",
      "[[  5.58374728e-05  -5.58374728e-05]\n",
      " [  1.19920045e-02  -1.19920045e-02]\n",
      " [ -8.70825239e-03   8.70825239e-03]\n",
      " [  4.81714635e-03  -4.81714635e-03]\n",
      " [  8.95784140e-08  -8.95784148e-08]]\n",
      "theta policy diff norm:  0.0220385955951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5.27708867, -5.27708867],\n",
       "       [ 2.57672771, -2.57672771],\n",
       "       [ 2.80584239, -2.80584239],\n",
       "       [ 3.20208722, -3.20208722],\n",
       "       [ 9.67515749, -9.67515749]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_gradient_algo(P, R , discount,  path_len=10, gamma = 10.0, logging = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare with other existing method  - policy iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal policy (policy iteration) : \n",
      "(0, 0, 0, 0, 0)\n",
      "Optimal policy (policy gradient) :\n",
      "[[  9.81144265e-01   1.88557345e-02]\n",
      " [  7.74703842e-07   9.99999225e-01]\n",
      " [  9.93717305e-01   6.28269535e-03]\n",
      " [  9.99345680e-01   6.54320200e-04]\n",
      " [  1.00000000e+00   1.16757323e-10]]\n"
     ]
    }
   ],
   "source": [
    "import mdptoolbox_copy\n",
    "pi =  mdptoolbox_copy.mdp.PolicyIteration(P, R, discount=discount)\n",
    "pi.policy0=[1,1,1,1,1]\n",
    "#vi.setVerbose()\n",
    "pi.run()\n",
    "\n",
    "policy_pi = pi.policy\n",
    "\n",
    "print \"Optimal policy (policy iteration) : \\n\" , policy_pi\n",
    "\n",
    "policy_pg  = policy_gradient_algo( P, R , discount , path_len ,  n_paths, gamma=10 , eps=0.01)\n",
    "\n",
    "print \"Optimal policy (policy gradient) :\\n\" , mu_policy(policy_pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mdptoolbox_copy.example as mdp_ex\n",
    "\n",
    "n_states = 5\n",
    "n_actions = 2\n",
    "fire_prob = 0.1\n",
    "discount=0.9\n",
    "n_paths=100\n",
    "path_len=100\n",
    "path_len = 10\n",
    "path_num = 10\n",
    "\n",
    "P, R = mdp_ex.forest(S=n_states, p=fire_prob)\n",
    "\n",
    "def generate_rollout(mu_policy, transition_matrix, reward_matrix, discount, path_len=10) : \n",
    "    n_states, n_actions = mu_policy.shape\n",
    "    path_action = np.zeros(path_len , dtype=int)\n",
    "    path_state = np.zeros(path_len, dtype=int)\n",
    "    path_state[0] = rand.random_integers(n_states) -1\n",
    "    path_action[0] = np.random.choice(n_actions, 1, p=mu_policy[path_state[0]])\n",
    "    path_reward =  reward_matrix[path_state[0], path_action[0]]\n",
    "    for i in range(1, path_len) :\n",
    "        path_state[i] = np.random.choice(n_states , 1, p=transition_matrix[path_action[i-1]][path_state[i-1]])\n",
    "        path_action[i] = np.random.choice(n_actions, 1, p=mu_policy[path_state[i]])\n",
    "        path_reward =  path_reward + discount**i * reward_matrix[path_state[i], path_action[i]]\n",
    "    return path_state, path_action, path_reward\n",
    "\n",
    "\n",
    "def generate_rollouts(mu_policy, transition_matrix, reward_matrix, discount, path_len=10, n_paths=10):\n",
    "    n_states, n_actions = mu_policy.shape \n",
    "    paths_states = np.zeros(( n_paths , path_len), dtype=int)\n",
    "    paths_actions = np.zeros(( n_paths , path_len), dtype=int)\n",
    "    paths_rewards = np.zeros( n_paths  )\n",
    "    for i in range(0, n_paths) : \n",
    "        paths_states[i], paths_actions[i], paths_rewards[i] = generate_rollout(mu_policy, transition_matrix, reward_matrix, discount, path_len)\n",
    "    return paths_states, paths_actions, paths_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need function to generate rollouts from our policy. This will generate trajectories of our model under policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 1 0]\n",
      " [3 4 4 0 0]\n",
      " [3 0 0 1 2]\n",
      " [3 4 0 1 0]\n",
      " [1 2 0 0 1]\n",
      " [3 0 0 0 0]\n",
      " [4 0 1 0 1]\n",
      " [3 0 0 1 0]\n",
      " [2 3 4 4 4]\n",
      " [4 0 1 0 1]] [[0 1 0 0 1]\n",
      " [0 0 1 1 0]\n",
      " [1 1 0 0 0]\n",
      " [0 1 0 1 1]\n",
      " [0 1 1 0 1]\n",
      " [1 1 1 1 0]\n",
      " [0 0 1 0 0]\n",
      " [1 1 0 1 1]\n",
      " [0 0 0 0 1]\n",
      " [1 0 1 0 1]] [ 0.      5.22    1.      2.529   1.5561  1.      4.81    1.729   7.4682\n",
      "  3.4661]\n"
     ]
    }
   ],
   "source": [
    "paths_states, paths_actions, paths_rewards = generate_rollouts(mu, P, R, discount, path_len=5, n_paths=10)\n",
    "print paths_states, paths_actions, paths_rewards"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
